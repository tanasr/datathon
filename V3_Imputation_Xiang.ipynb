{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 #make sure to automatically load externally updated files\n",
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,MaxAbsScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from helper import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,mean_squared_log_error\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler,MaxAbsScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit, cross_val_score,cross_validate,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.metrics import balanced_accuracy_score,precision_score,recall_score\n",
    "from sklearn.svm import SVC\n",
    "from pandas.plotting import scatter_matrix\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "def print_info(variable_name):\n",
    "    print(\"---\", variable_name, \"     type = \", type(eval(variable_name)), \"     Value = \", eval(variable_name),\" --- \")\n",
    "\n",
    "def print_infos(*variable_names):\n",
    "    \"\"\"\n",
    "        Prints information about the variables\n",
    "\n",
    "        Example: print_infos('var1','var2')\n",
    "    \"\"\"\n",
    "    for variable_name in variable_names:\n",
    "        print(\"---\", variable_name, \"     type = \", type(eval(variable_name)), \"     Value = \", eval(variable_name),\" --- \")\n",
    "\n",
    "def print_types(*variable_names,print_shape=True):\n",
    "    \"\"\"\n",
    "        Prints types about the variables\n",
    "\n",
    "        :param print_shape(bool): Prints shape of variables (Needs them to be a np array, DataFrame or Series)\n",
    "\n",
    "        Example: print_types('var1','var2')\n",
    "    \"\"\"\n",
    "    for variable_name in variable_names:\n",
    "        if not print_shape:\n",
    "            print(\"---\", variable_name, \"     type = \", type(eval(variable_name)))\n",
    "        if print_shape:\n",
    "            print(\"---\", variable_name, \"     type = \", type(eval(variable_name)),end=\"\") #makes to to not have a new line\n",
    "            try:\n",
    "                print(\"     Shape = \", eval(variable_name).shape,\" --- \\n\")\n",
    "            except:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./data/trainset.csv\")\n",
    "if False:\n",
    "    data.head(10000).to_excel(\"./data/trainset.xlsx\")\n",
    "data=data.drop([\"index\"],axis=1)\n",
    "\n",
    "data['error'] = (data['error_category'] != 'NO_ERROR').astype(int)\n",
    "\n",
    "data_full=pd.read_csv(\"./data/trainset_full.csv\")\n",
    "data_full=data_full.drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_nan=['wind_speed', 'power', 'rotor_speed', 'generator_speed', 'temp_environment', 'temp_hydraulic_oil', 'temp_gear_bearing', 'blade_angle_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_imputation(data,data_pred,data_full,column,print_result=False):\n",
    "    \"\"\"\n",
    "        Evaluate the imputaton accuracy of a specific column\n",
    "        \n",
    "        returns ||y_pred-y_true||_2/ (num_nan_values) for the column specified\n",
    "\n",
    "        :param data: raw training data\n",
    "        :param column (str): column name \n",
    "    \"\"\"\n",
    "    num_nan_values=int(data.loc[:,[column]].isnull().sum())\n",
    "    sum_of_squares=float(np.sum((data_pred.loc[:,[column]]-data_full.loc[:,[column]])**2))\n",
    "    average_error=np.sqrt(sum_of_squares)/num_nan_values\n",
    "\n",
    "    if print_result:\n",
    "        print(\"--- Column \", column, \" imputation--- with \",num_nan_values ,\" num_nan_values: \")\n",
    "        print(\"(Average || ||_2) absolute error: \",average_error)\n",
    "    return average_error,num_nan_values\n",
    "\n",
    "def evaluate_imputation_single_column(data_pred,data_true,column):\n",
    "    \"\"\"\n",
    "    calculates r2 score of specific imputed column\n",
    "\n",
    "    @param column (str): the column to evaluate\n",
    "    \"\"\"\n",
    "    missing_mask=data[column].isna()\n",
    "    r2=r2_score(\n",
    "        y_true=np.array(data_true[column][missing_mask]), #only those columns with nan values\n",
    "        y_pred=np.array(data_pred[column][missing_mask])\n",
    "    )\n",
    "    return r2\n",
    "\n",
    "def evaluate_impuation(data_pred,data_true):\n",
    "    print(\"R2 score of imputation\")\n",
    "    for column in features_with_nan:\n",
    "        r2=evaluate_imputation_single_column(data_pred,data_full,column)\n",
    "        print(r2, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: how to use evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7229440668866738\n"
     ]
    }
   ],
   "source": [
    "column=\"wind_speed\"\n",
    "data_pred=data.ffill()\n",
    "\n",
    "print(evaluate_imputation_single_column(data_pred,data_full,column))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score of imputation\n",
      "0.7229440668866738 wind_speed\n",
      "0.7394281474530568 power\n",
      "0.5387601939311892 rotor_speed\n",
      "0.5724850955915846 generator_speed\n",
      "0.9706766580278108 temp_environment\n",
      "0.9792879186765434 temp_hydraulic_oil\n",
      "0.8906588997410945 temp_gear_bearing\n",
      "0.24649833536166954 blade_angle_avg\n"
     ]
    }
   ],
   "source": [
    "data_pred=data.ffill()\n",
    "evaluate_impuation(data_pred,data_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_without_nan(data,feature_to_be_imputed):\n",
    "    \"\"\"\n",
    "        only returns the rows where the specific column (\"feature_to_be_imputed\") is not NaN\n",
    "        @feature_to_be_imputed (str): name of column\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    data_without_nan =data[data[feature_to_be_imputed].notnull()] #dataframe. only rows s.t. feature_imputed is not nan\n",
    "    return data_without_nan\n",
    "\n",
    "def create_X_y_for_single_feature_imputation(data_without_nan,feature_to_be_imputed):\n",
    "    \"\"\"\n",
    "        Creats X, and y. Only uses the columns without NaN values in this feature\n",
    "\n",
    "        @data (DataFrame): the data dataframe\n",
    "        @param feature_to_be_imputed (str): name of column to be imputed ^= y\n",
    "\n",
    "        @return X,y \n",
    "    \"\"\"\n",
    "\n",
    "    y=data_without_nan[feature_to_be_imputed]\n",
    "\n",
    "    feat_temp=['turbine_id', 'wind_speed', 'power', 'nacelle_direction',\n",
    "    'wind_direction' ,'rotor_speed', 'generator_speed' ,'temp_environment'\n",
    "    ,'temp_hydraulic_oil' ,'temp_gear_bearing' ,'cosphi' ,'blade_angle_avg',\n",
    "    'hydraulic_pressure', 'park_id']\n",
    "    X=data_without_nan[feat_temp]\n",
    "    X=X.drop([feature_to_be_imputed],axis=1)\n",
    "\n",
    "    return X,y\n",
    "\n",
    "#How to use it\n",
    "if False:\n",
    "    feature_to_be_imputed=\"wind_speed\"\n",
    "    X,y=create_X_y_for_single_feature_imputation(data,feature_to_be_imputed)\n",
    "\n",
    "    print_infos('X.head()','y.head()')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Starting with  wind_speed\n",
      "0.989544594398575 wind_speed [0.98938594 0.9896638  0.98947846 0.98938253 0.98947286 0.98947192\n",
      " 0.98978693 0.9897143 ]\n",
      "-- Starting with  power\n",
      "0.9950065196247153 power [0.99502275 0.9950746  0.99485842 0.99500359 0.99494273 0.99508168\n",
      " 0.99502771 0.99504068]\n",
      "-- Starting with  rotor_speed\n",
      "0.9997682916616242 rotor_speed [0.99977017 0.99977193 0.9997573  0.99977915 0.99975635 0.99976446\n",
      " 0.99977795 0.99976903]\n",
      "-- Starting with  generator_speed\n",
      "0.9996675422162713 generator_speed [0.99966839 0.99966724 0.99966497 0.9996655  0.99966926 0.99966739\n",
      " 0.99966794 0.99966964]\n",
      "-- Starting with  temp_environment\n",
      "0.6340898079998434 temp_environment [0.63580387 0.63505672 0.63325894 0.63244797 0.63286099 0.63582767\n",
      " 0.63367803 0.63378427]\n",
      "-- Starting with  temp_hydraulic_oil\n",
      "0.9470137324468012 temp_hydraulic_oil [0.94781703 0.94710144 0.94694142 0.94747793 0.9463428  0.94730556\n",
      " 0.94701167 0.94611202]\n",
      "-- Starting with  temp_gear_bearing\n",
      "0.940280830353346 temp_gear_bearing [0.94024931 0.94027022 0.94027298 0.93988377 0.9405166  0.94028664\n",
      " 0.94027232 0.9404948 ]\n",
      "-- Starting with  blade_angle_avg\n",
      "0.9868741411051904 blade_angle_avg [0.98679068 0.9862811  0.98714597 0.98655331 0.98779776 0.98688959\n",
      " 0.98699498 0.98653974]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Predict one feature using others. D\n",
    "\"\"\"\n",
    "action=1\n",
    "match action:\n",
    "    case 1:\n",
    "        features_to_be_imputed=features_with_nan\n",
    "    case 2:\n",
    "        features_to_be_imputed=[\"temp_hydraulic_oil\"]\n",
    "\n",
    "model=LGBMRegressor()\n",
    "\n",
    "for feature_to_be_imputed in features_to_be_imputed:\n",
    "    print(\"-- Starting with \", feature_to_be_imputed)\n",
    "\n",
    "    #Get DataFram where there is no NaN values in this column\n",
    "    data_without_nan=get_data_without_nan(data,feature_to_be_imputed)\n",
    "\n",
    "    X,y=create_X_y_for_single_feature_imputation(data_full,feature_to_be_imputed)\n",
    "\n",
    "\n",
    "    action=2\n",
    "    match action:\n",
    "        #Evaluate using single train test split\n",
    "        case 1:\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.5)\n",
    "            #print_types(\"X_train\",\"X_test\",\"y_train\",\"y_test\") #print shapes\n",
    "\n",
    "            model.fit(X_train,y_train)\n",
    "            y_pred=model.predict(X_test)\n",
    "            score=r2_score(y_test,y_pred)\n",
    "            print(score,feature_to_be_imputed)\n",
    "        #Evaluate using CV\n",
    "        case 2:\n",
    "            kfold = KFold(n_splits=8, shuffle=True)\n",
    "            score_dict=cross_validate(model,X,y,cv=kfold,scoring=\"r2\")\n",
    "            scores=score_dict[\"test_score\"]\n",
    "            print(np.mean(scores),feature_to_be_imputed,scores)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [410158, 957032]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\7Temporary\\Coding\\Github\\2022_05_14_Datathon_2022_V2\\datathon\\V3_Imputation_Xiang.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/7Temporary/Coding/Github/2022_05_14_Datathon_2022_V2/datathon/V3_Imputation_Xiang.ipynb#ch0000011?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/7Temporary/Coding/Github/2022_05_14_Datathon_2022_V2/datathon/V3_Imputation_Xiang.ipynb#ch0000011?line=11'>12</a>\u001b[0m y_pred\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive/7Temporary/Coding/Github/2022_05_14_Datathon_2022_V2/datathon/V3_Imputation_Xiang.ipynb#ch0000011?line=12'>13</a>\u001b[0m score\u001b[39m=\u001b[39mr2_score(y_test,y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/7Temporary/Coding/Github/2022_05_14_Datathon_2022_V2/datathon/V3_Imputation_Xiang.ipynb#ch0000011?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(score)\n",
      "File \u001b[1;32md:\\OneDrive\\7Temporary\\Coding\\Github\\.venv_learning_python_April_2022_V2\\lib\\site-packages\\sklearn\\metrics\\_regression.py:789\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=701'>702</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr2_score\u001b[39m(y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=702'>703</a>\u001b[0m     \u001b[39m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=703'>704</a>\u001b[0m \n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=704'>705</a>\u001b[0m \u001b[39m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=786'>787</a>\u001b[0m \u001b[39m    -3.0\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=787'>788</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=788'>789</a>\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=789'>790</a>\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=790'>791</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=791'>792</a>\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=793'>794</a>\u001b[0m     \u001b[39mif\u001b[39;00m _num_samples(y_pred) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32md:\\OneDrive\\7Temporary\\Coding\\Github\\.venv_learning_python_April_2022_V2\\lib\\site-packages\\sklearn\\metrics\\_regression.py:94\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=59'>60</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=60'>61</a>\u001b[0m     \u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=61'>62</a>\u001b[0m \n\u001b[0;32m     <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=62'>63</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=91'>92</a>\u001b[0m \u001b[39m        the dtype argument passed to check_array.\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=92'>93</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=93'>94</a>\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=94'>95</a>\u001b[0m     y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m     <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/metrics/_regression.py?line=95'>96</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[1;32md:\\OneDrive\\7Temporary\\Coding\\Github\\.venv_learning_python_April_2022_V2\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/utils/validation.py?line=329'>330</a>\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/utils/validation.py?line=330'>331</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/utils/validation.py?line=331'>332</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/utils/validation.py?line=332'>333</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/utils/validation.py?line=333'>334</a>\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    <a href='file:///d%3A/OneDrive/7Temporary/Coding/Github/.venv_learning_python_April_2022_V2/lib/site-packages/sklearn/utils/validation.py?line=334'>335</a>\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [410158, 957032]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model=LGBMRegressor()\n",
    "#scoreMult_regr(model,X,y,train_size=0.5,ntimes=1,printAllScores=False,batchDisplay=True)\n",
    "\n",
    "#print(type(X.head()))\n",
    "#print(X.head().dtypes)\n",
    "#print(y.head().dtypes)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.7)\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "score=r2_score(y_test,y_train)\n",
    "print(score)\n",
    "\n",
    "#CV(model, X,y,nsplits=3,ntimes=1,printIntRes=True,printRes=True,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1579b12db5982dc3bdb298a2d2bb68e534f93f25a15b58e9be726e03ebea9e10"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv_learning_python_April_2022_V2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
