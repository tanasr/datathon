{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 #make sure to automatically load externally updated files\n",
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,MaxAbsScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from helper import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,mean_squared_log_error\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler,MaxAbsScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit, cross_val_score,cross_validate,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.metrics import balanced_accuracy_score,precision_score,recall_score\n",
    "from sklearn.svm import SVC\n",
    "from pandas.plotting import scatter_matrix\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "def print_info(variable_name):\n",
    "    print(\"---\", variable_name, \"     type = \", type(eval(variable_name)), \"     Value = \", eval(variable_name),\" --- \")\n",
    "\n",
    "def print_infos(*variable_names):\n",
    "    \"\"\"\n",
    "        Prints information about the variables\n",
    "\n",
    "        Example: print_infos('var1','var2')\n",
    "    \"\"\"\n",
    "    for variable_name in variable_names:\n",
    "        print(\"---\", variable_name, \"     type = \", type(eval(variable_name)), \"     Value = \", eval(variable_name),\" --- \")\n",
    "\n",
    "def print_types(*variable_names,print_shape=True):\n",
    "    \"\"\"\n",
    "        Prints types about the variables\n",
    "\n",
    "        :param print_shape(bool): Prints shape of variables (Needs them to be a np array, DataFrame or Series)\n",
    "\n",
    "        Example: print_types('var1','var2')\n",
    "    \"\"\"\n",
    "    for variable_name in variable_names:\n",
    "        if not print_shape:\n",
    "            print(\"---\", variable_name, \"     type = \", type(eval(variable_name)))\n",
    "        if print_shape:\n",
    "            print(\"---\", variable_name, \"     type = \", type(eval(variable_name)),end=\"\") #makes to to not have a new line\n",
    "            try:\n",
    "                print(\"     Shape = \", eval(variable_name).shape,\" --- \\n\")\n",
    "            except:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./data/trainset.csv\")\n",
    "if False:\n",
    "    data.head(10000).to_excel(\"./data/trainset.xlsx\")\n",
    "data=data.drop([\"index\"],axis=1)\n",
    "\n",
    "data['error'] = (data['error_category'] != 'NO_ERROR').astype(int)\n",
    "\n",
    "data_full=pd.read_csv(\"./data/trainset_full.csv\")\n",
    "data_full=data_full.drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_nan=['wind_speed', 'power', 'rotor_speed', 'generator_speed', 'temp_environment', 'temp_hydraulic_oil', 'temp_gear_bearing', 'blade_angle_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_imputation(data,data_pred,data_full,column,print_result=False):\n",
    "    \"\"\"\n",
    "        Evaluate the imputaton accuracy of a specific column\n",
    "        \n",
    "        returns ||y_pred-y_true||_2/ (num_nan_values) for the column specified\n",
    "\n",
    "        :param data: raw training data\n",
    "        :param column (str): column name \n",
    "    \"\"\"\n",
    "    num_nan_values=int(data.loc[:,[column]].isnull().sum())\n",
    "    sum_of_squares=float(np.sum((data_pred.loc[:,[column]]-data_full.loc[:,[column]])**2))\n",
    "    average_error=np.sqrt(sum_of_squares)/num_nan_values\n",
    "\n",
    "    if print_result:\n",
    "        print(\"--- Column \", column, \" imputation--- with \",num_nan_values ,\" num_nan_values: \")\n",
    "        print(\"(Average || ||_2) absolute error: \",average_error)\n",
    "    return average_error,num_nan_values\n",
    "\n",
    "def evaluate_imputation_single_column(data_pred,data_true,column):\n",
    "    \"\"\"\n",
    "    calculates r2 score of specific imputed column\n",
    "\n",
    "    @param column (str): the column to evaluate\n",
    "    \"\"\"\n",
    "    missing_mask=data[column].isna()\n",
    "    r2=r2_score(\n",
    "        y_true=np.array(data_true[column][missing_mask]), #only those columns with nan values\n",
    "        y_pred=np.array(data_pred[column][missing_mask])\n",
    "    )\n",
    "    return r2\n",
    "\n",
    "def evaluate_impuation(data_pred,data_true):\n",
    "    print(\"R2 score of imputation\")\n",
    "    for column in features_with_nan:\n",
    "        r2=evaluate_imputation_single_column(data_pred,data_full,column)\n",
    "        print(r2, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: how to use evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7229440668866738\n"
     ]
    }
   ],
   "source": [
    "column=\"wind_speed\"\n",
    "data_pred=data.ffill()\n",
    "\n",
    "print(evaluate_imputation_single_column(data_pred,data_full,column))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score of imputation\n",
      "0.7229440668866738 wind_speed\n",
      "0.7394281474530568 power\n",
      "0.5387601939311892 rotor_speed\n",
      "0.5724850955915846 generator_speed\n",
      "0.9706766580278108 temp_environment\n",
      "0.9792879186765434 temp_hydraulic_oil\n",
      "0.8906588997410945 temp_gear_bearing\n",
      "0.24649833536166954 blade_angle_avg\n"
     ]
    }
   ],
   "source": [
    "data_pred=data.ffill()\n",
    "evaluate_impuation(data_pred,data_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_without_nan(data,feature_to_be_imputed):\n",
    "    \"\"\"\n",
    "        only returns the rows where the specific column (\"feature_to_be_imputed\") is not NaN\n",
    "        @feature_to_be_imputed (str): name of column\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    data_without_nan =data[data[feature_to_be_imputed].notnull()] #dataframe. only rows s.t. feature_imputed is not nan\n",
    "    return data_without_nan\n",
    "\n",
    "def create_X_y_for_single_feature_imputation(data_without_nan,feature_to_be_imputed):\n",
    "    \"\"\"\n",
    "        Creats X, and y. Only uses the columns without NaN values in this feature\n",
    "\n",
    "        @data (DataFrame): the data dataframe\n",
    "        @param feature_to_be_imputed (str): name of column to be imputed ^= y\n",
    "\n",
    "        @return X,y \n",
    "    \"\"\"\n",
    "\n",
    "    y=data_without_nan[feature_to_be_imputed]\n",
    "\n",
    "    feat_temp=['turbine_id', 'wind_speed', 'power', 'nacelle_direction',\n",
    "    'wind_direction' ,'rotor_speed', 'generator_speed' ,'temp_environment'\n",
    "    ,'temp_hydraulic_oil' ,'temp_gear_bearing' ,'cosphi' ,'blade_angle_avg',\n",
    "    'hydraulic_pressure', 'park_id']\n",
    "    X=data_without_nan[feat_temp]\n",
    "    X=X.drop([feature_to_be_imputed],axis=1)\n",
    "\n",
    "    return X,y\n",
    "\n",
    "#How to use it\n",
    "if False:\n",
    "    feature_to_be_imputed=\"wind_speed\"\n",
    "    X,y=create_X_y_for_single_feature_imputation(data,feature_to_be_imputed)\n",
    "\n",
    "    print_infos('X.head()','y.head()')\n",
    "\n",
    "def impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Starting with  wind_speed\n",
      "0.98957363656266 wind_speed [0.98988018 0.98973896 0.98944677 0.98974453 0.98941914 0.98942062\n",
      " 0.98965204 0.98928685]\n",
      "-- Starting with  power\n",
      "0.9950023063989042 power [0.99511665 0.99500695 0.99488762 0.99505562 0.99500966 0.99501187\n",
      " 0.99500337 0.99492672]\n",
      "-- Starting with  rotor_speed\n",
      "0.9997661654961133 rotor_speed [0.99976769 0.99976203 0.99977555 0.99975858 0.99977107 0.99977164\n",
      " 0.99976316 0.9997596 ]\n",
      "-- Starting with  generator_speed\n",
      "0.9996683807676511 generator_speed [0.99966693 0.99966961 0.99966786 0.99967276 0.99966755 0.99966964\n",
      " 0.99966673 0.99966596]\n",
      "-- Starting with  temp_environment\n",
      "0.6340246721750237 temp_environment [0.63649327 0.63110448 0.63442346 0.63311286 0.63583982 0.63581842\n",
      " 0.63207765 0.63332742]\n",
      "-- Starting with  temp_hydraulic_oil\n",
      "0.9471129370672481 temp_hydraulic_oil [0.94554809 0.94654522 0.94840707 0.94661568 0.94707744 0.94802196\n",
      " 0.94738144 0.94730659]\n",
      "-- Starting with  temp_gear_bearing\n",
      "0.9402951409086397 temp_gear_bearing [0.94005737 0.94027957 0.93982291 0.94110664 0.94054841 0.94005167\n",
      " 0.93994652 0.94054803]\n",
      "-- Starting with  blade_angle_avg\n",
      "0.9869150516619389 blade_angle_avg [0.98702548 0.98642871 0.98683091 0.98718376 0.98748257 0.98654562\n",
      " 0.98709286 0.9867305 ]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Predict one feature using others. D\n",
    "\"\"\"\n",
    "action=1\n",
    "match action:\n",
    "    case 1:\n",
    "        features_to_be_imputed=features_with_nan\n",
    "    case 2:\n",
    "        features_to_be_imputed=[\"temp_hydraulic_oil\"]\n",
    "\n",
    "model=LGBMRegressor()\n",
    "\n",
    "for feature_to_be_imputed in features_to_be_imputed:\n",
    "    print(\"-- Starting with \", feature_to_be_imputed)\n",
    "\n",
    "    #Get DataFram where there is no NaN values in this column\n",
    "    data_without_nan=get_data_without_nan(data,feature_to_be_imputed)\n",
    "\n",
    "    X,y=create_X_y_for_single_feature_imputation(data_full,feature_to_be_imputed)\n",
    "\n",
    "\n",
    "    action=2\n",
    "    match action:\n",
    "        #Evaluate using single train test split\n",
    "        case 1:\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.5)\n",
    "            #print_types(\"X_train\",\"X_test\",\"y_train\",\"y_test\") #print shapes\n",
    "\n",
    "            model.fit(X_train,y_train)\n",
    "            y_pred=model.predict(X_test)\n",
    "            score=r2_score(y_test,y_pred)\n",
    "            print(score,feature_to_be_imputed)\n",
    "        #Evaluate using CV\n",
    "        case 2:\n",
    "            kfold = KFold(n_splits=8, shuffle=True)\n",
    "            score_dict=cross_validate(model,X,y,cv=kfold,scoring=\"r2\")\n",
    "            scores=score_dict[\"test_score\"]\n",
    "            print(np.mean(scores),feature_to_be_imputed,scores)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1579b12db5982dc3bdb298a2d2bb68e534f93f25a15b58e9be726e03ebea9e10"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv_learning_python_April_2022_V2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
